# ðŸ—ï¸ Architecture de MyFlow

## ðŸ“‹ Vue d'ensemble

MyFlow est une mini-librairie d'orchestration de workflows conÃ§ue avec les meilleurs design patterns pour assurer la maintenabilitÃ©, l'extensibilitÃ© et la robustesse.

## ðŸŽ¯ Design Patterns UtilisÃ©s

### 1. **Builder Pattern** - Construction des DAGs
```python
dag = (DAG.builder("my_dag")
       .set_description("Mon DAG")
       .add_task(task1)
       .add_dependency("task1", "task2")
       .build())
```

### 2. **Factory Pattern** - CrÃ©ation d'opÃ©rateurs
```python
operator = OperatorFactory.create_operator("python", "task_id", "dag_id", 
                                          python_callable=my_function)
```

### 3. **Template Method Pattern** - ExÃ©cution des tÃ¢ches
```python
class Task(ABC):
    def run(self):  # Template method
        self.pre_execute()
        success = self.execute()  # Hook method
        self.post_execute(success)
```

### 4. **Singleton Pattern** - Logger
```python
logger = Logger.get_instance()  # Une seule instance globale
```

### 5. **Strategy Pattern** - ExÃ©cuteurs
```python
executor = SequentialExecutor()  # ou ParallelExecutor()
```

## ðŸ“ Structure des Modules

```
myflow_lib/
â”œâ”€â”€ __init__.py              # Point d'entrÃ©e principal
â”œâ”€â”€ core/                    # Classes fondamentales
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ task.py             # Classe Task (Template Method)
â”‚   â”œâ”€â”€ dag.py              # Classe DAG (Builder Pattern)
â”‚   â””â”€â”€ scheduler.py        # Planificateur
â”œâ”€â”€ operators/              # OpÃ©rateurs (Factory Pattern)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_operator.py    # Classe de base
â”‚   â”œâ”€â”€ python_operator.py  # OpÃ©rateur Python
â”‚   â”œâ”€â”€ bash_operator.py    # OpÃ©rateur Bash
â”‚   â”œâ”€â”€ http_operator.py    # OpÃ©rateur HTTP
â”‚   â””â”€â”€ operator_factory.py # Factory des opÃ©rateurs
â”œâ”€â”€ executors/              # ExÃ©cuteurs (Strategy Pattern)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sequential_executor.py
â”‚   â””â”€â”€ parallel_executor.py
â””â”€â”€ utils/                  # Utilitaires
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ logger.py           # Logger (Singleton)
    â””â”€â”€ config.py           # Configuration
```

## ðŸ”„ Flux d'ExÃ©cution

### 1. **Construction du DAG**
```python
# Builder Pattern
dag = DAG.builder("my_dag").set_description("...").build()

# Factory Pattern
task = OperatorFactory.create_operator("python", "task1", "my_dag", 
                                      python_callable=my_function)
```

### 2. **Validation**
```python
if dag.validate():  # VÃ©rification des cycles
    # DAG valide
```

### 3. **ExÃ©cution**
```python
# Template Method Pattern
for task in dag.get_ready_tasks():
    task.run()  # pre_execute() -> execute() -> post_execute()
```

## ï¿½ï¿½ Arbre de DÃ©cision

### Niveau 1: Construction
```
DAGBuilder â†’ Validation â†’ DAG
```

### Niveau 2: ExÃ©cution
```
Task.run() â†’ pre_execute() â†’ execute() â†’ post_execute()
```

### Niveau 3: Gestion des Ã‰tats
```
PENDING â†’ RUNNING â†’ SUCCESS/FAILED/SKIPPED/RETRY
```

## ðŸŽ¨ Avantages de cette Architecture

### 1. **ExtensibilitÃ©**
- Nouveaux opÃ©rateurs via Factory Pattern
- Nouveaux exÃ©cuteurs via Strategy Pattern
- Configuration flexible via Config

### 2. **MaintenabilitÃ©**
- SÃ©paration claire des responsabilitÃ©s
- Code modulaire et testable
- Documentation intÃ©grÃ©e

### 3. **Robustesse**
- Gestion d'erreurs Ã  tous les niveaux
- MÃ©canisme de retry intÃ©grÃ©
- Validation des DAGs

### 4. **Performance**
- ExÃ©cution parallÃ¨le possible
- Gestion des ressources
- Optimisations configurables

## ï¿½ï¿½ Configuration

### Variables d'Environnement
```bash
export MYFLOW_MAX_WORKERS=4
export MYFLOW_LOG_LEVEL=INFO
export MYFLOW_TIMEOUT=300
```

### Configuration Programmatique
```python
from myflow_lib.utils.config import Config

config = Config()
config.executor.max_workers = 8
config.logging.level = "DEBUG"
```

## ðŸ§ª Tests

### Structure des Tests
```
tests/
â”œâ”€â”€ unit/                   # Tests unitaires
â”‚   â”œâ”€â”€ test_task.py
â”‚   â”œâ”€â”€ test_dag.py
â”‚   â””â”€â”€ test_operators.py
â”œâ”€â”€ integration/            # Tests d'intÃ©gration
â”‚   â”œâ”€â”€ test_infrastructure.py
â”‚   â””â”€â”€ test_workflows.py
â””â”€â”€ fixtures/              # DonnÃ©es de test
```

### ExÃ©cution des Tests
```bash
python scripts/run_tests.py
```

## ðŸ“š Exemples

### Exemples Disponibles
```
examples/
â”œâ”€â”€ simple_example.py       # Exemple basique
â”œâ”€â”€ infrastructure_example.py # VÃ©rifications d'infrastructure
â””â”€â”€ advanced_example.py     # Exemple avancÃ©
```

### ExÃ©cution des Exemples
```bash
python scripts/run_examples.py
```

## ðŸš€ Utilisation

### Import Simple
```python
from myflow_lib import DAG, PythonOperator, BashOperator
```

### Construction Fluide
```python
dag = (DAG.builder("my_workflow")
       .set_description("Mon workflow")
       .add_task(PythonOperator("task1", "my_workflow", my_function))
       .add_task(BashOperator("task2", "my_workflow", "echo hello"))
       .add_dependency("task1", "task2")
       .build())
```

### ExÃ©cution
```python
for task in dag.get_execution_order():
    task.run()
```

Cette architecture garantit un code propre, maintenable et extensible, tout en offrant une API intuitive et puissante pour l'orchestration de workflows.
