# ï¿½ï¿½ Guide du Workflow d'Ingestion YouTube

## ğŸ“‹ Vue d'ensemble

Ce guide vous explique comment utiliser le workflow MyFlow pour l'ingestion des donnÃ©es YouTube :
**YouTube API â†’ MongoDB â†’ Spark â†’ HDFS**

## ğŸ—ï¸ Architecture du Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   YouTube API   â”‚â”€â”€â”€â–¶â”‚   MongoDB    â”‚â”€â”€â”€â–¶â”‚    Spark    â”‚â”€â”€â”€â–¶â”‚    HDFS     â”‚
â”‚                 â”‚    â”‚              â”‚    â”‚             â”‚    â”‚             â”‚
â”‚ â€¢ Extraction    â”‚    â”‚ â€¢ Stockage   â”‚    â”‚ â€¢ ETL       â”‚    â”‚ â€¢ Stockage  â”‚
â”‚ â€¢ DonnÃ©es brutesâ”‚    â”‚ â€¢ DonnÃ©es    â”‚    â”‚ â€¢ Transform â”‚    â”‚ â€¢ Final     â”‚
â”‚                 â”‚    â”‚   brutes     â”‚    â”‚ â€¢ Clean     â”‚    â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Ã‰tapes de DÃ©marrage

### 1. DÃ©marrer l'Infrastructure

```bash
# Aller dans le rÃ©pertoire racine du projet
cd /Users/finnhuman/Documents/TD_groupe_Datalake/Ad_Trackr

# DÃ©marrer tous les services
docker-compose up -d

# VÃ©rifier que tous les services sont en cours
docker-compose ps
```

### 2. VÃ©rifier la Configuration

```bash
# Aller dans le dossier myflow
cd myflow

# Activer l'environnement virtuel
source venv/bin/activate

# Tester la faisabilitÃ©
python scripts/test_youtube_workflow.py
```

### 3. ExÃ©cuter le Workflow

```bash
# ExÃ©cuter le workflow complet
python examples/youtube_ingestion_workflow.py
```

## ğŸ”§ Configuration Requise

### Variables d'Environnement (.env)
```bash
# YouTube Data API v3
YOUTUBE_API_KEY=your_youtube_api_key_here

# MongoDB Configuration  
MONGO_URI=mongodb://admin:password123@mongo:27017/
MONGO_USERNAME=admin
MONGO_PASSWORD=password123
MONGO_DATABASE=datalake

# HDFS Configuration
HDFS_NAMENODE_URL=hdfs://namenode:9000
HDFS_BASE_PATH=/user/influencers_analysis

# Spark Configuration
SPARK_MASTER_URL=spark://spark-master:7077
```

### Services Docker Requis
- `datalake-mongo` : Base de donnÃ©es MongoDB
- `datalake-namenode` : HDFS NameNode
- `datalake-spark-master` : Spark Master

## ğŸ“Š Workflow DÃ©taillÃ©

### TÃ¢che 1: VÃ©rification de l'Environnement
- âœ… Variables d'environnement prÃ©sentes
- âœ… ClÃ© API YouTube valide

### TÃ¢che 2: VÃ©rification de la SantÃ© des Services
- âœ… MongoDB accessible
- âœ… HDFS accessible

### TÃ¢che 3: Extraction YouTube â†’ MongoDB
- ğŸ¬ Appel API YouTube Data v3
- ğŸ“Š Extraction des donnÃ©es des influenceurs
- ğŸ’¾ Stockage dans MongoDB (collection `raw_data`)

### TÃ¢che 4: ETL Spark (MongoDB â†’ HDFS)
- ğŸ”„ Lecture des donnÃ©es depuis MongoDB
- ğŸ§¹ Transformation et nettoyage
- ï¿½ï¿½ Stockage final dans HDFS

### TÃ¢che 5: VÃ©rification Finale
- ğŸ“Š Comptage des documents dans MongoDB
- âœ… VÃ©rification des fichiers dans HDFS

## ğŸ§ª Tests de Validation

### Test de FaisabilitÃ©
```bash
python scripts/test_youtube_workflow.py
```

**RÃ©sultats attendus :**
- âœ… Services Docker: PASS
- âœ… Variables d'environnement: PASS  
- âœ… Scripts disponibles: PASS
- âœ… Connexion MongoDB: PASS
- âœ… Connexion HDFS: PASS
- âœ… API YouTube: PASS

### Test du Workflow Complet
```bash
python examples/youtube_ingestion_workflow.py
```

**RÃ©sultats attendus :**
- âœ… Toutes les tÃ¢ches rÃ©ussies
- ğŸ“Š DonnÃ©es dans MongoDB
- ğŸ’¾ DonnÃ©es dans HDFS

## ğŸ” Monitoring et Debugging

### Logs du Workflow
Le workflow MyFlow gÃ©nÃ¨re des logs dÃ©taillÃ©s :
```
2025-08-29 09:30:00 - myflow - INFO - DÃ©marrage de l'extraction YouTube vers MongoDB
2025-08-29 09:30:05 - myflow - INFO - Extraction YouTube terminÃ©e avec succÃ¨s
2025-08-29 09:30:10 - myflow - INFO - DÃ©marrage de l'ETL Spark (MongoDB vers HDFS)
2025-08-29 09:30:30 - myflow - INFO - ETL Spark terminÃ© avec succÃ¨s
```

### VÃ©rification des DonnÃ©es

#### MongoDB
```bash
# Se connecter Ã  MongoDB
docker exec -it datalake-mongo mongosh

# VÃ©rifier les donnÃ©es
use datalake
db.raw_data.countDocuments({})
db.raw_data.findOne()
```

#### HDFS
```bash
# Lister les fichiers dans HDFS
docker exec datalake-namenode hdfs dfs -ls /user/influencers_analysis

# VÃ©rifier le contenu
docker exec datalake-namenode hdfs dfs -cat /user/influencers_analysis/part-00000
```

## ğŸš¨ RÃ©solution de ProblÃ¨mes

### ProblÃ¨me: Services Docker non dÃ©marrÃ©s
```bash
# Solution
docker-compose up -d
docker-compose ps
```

### ProblÃ¨me: Erreur de connexion MongoDB
```bash
# VÃ©rifier que MongoDB est dÃ©marrÃ©
docker logs datalake-mongo

# VÃ©rifier la configuration
echo $MONGO_URI
```

### ProblÃ¨me: Erreur API YouTube
```bash
# VÃ©rifier la clÃ© API
echo $YOUTUBE_API_KEY

# Tester manuellement
curl "https://www.googleapis.com/youtube/v3/search?key=$YOUTUBE_API_KEY&part=snippet&q=test&maxResults=1"
```

### ProblÃ¨me: Erreur HDFS
```bash
# VÃ©rifier que HDFS est dÃ©marrÃ©
docker logs datalake-namenode

# VÃ©rifier l'espace disque
docker exec datalake-namenode hdfs dfsadmin -report
```

## ğŸ“ˆ MÃ©triques de Performance

### Temps d'ExÃ©cution Typiques
- **VÃ©rification environnement** : ~1 seconde
- **VÃ©rification services** : ~5 secondes
- **Extraction YouTube** : ~30-60 secondes
- **ETL Spark** : ~2-5 minutes
- **VÃ©rification finale** : ~5 secondes

### Volume de DonnÃ©es
- **DonnÃ©es brutes** : ~1-10 MB par extraction
- **DonnÃ©es transformÃ©es** : ~500 KB - 5 MB
- **FrÃ©quence recommandÃ©e** : Quotidienne

## ğŸ¯ Prochaines Ã‰tapes

1. **Automatisation** : Planifier l'exÃ©cution quotidienne
2. **Monitoring** : Ajouter des alertes en cas d'Ã©chec
3. **Optimisation** : ParallÃ©liser les extractions
4. **Analytics** : CrÃ©er des dashboards de monitoring

## ğŸ“ Support

En cas de problÃ¨me :
1. VÃ©rifiez les logs du workflow
2. Consultez les logs Docker des services
3. Testez chaque composant individuellement
4. VÃ©rifiez la configuration des variables d'environnement

---

**MyFlow YouTube Workflow** - Pipeline d'ingestion automatisÃ© ğŸ¬ğŸš€
