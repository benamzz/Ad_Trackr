#!/bin/bash

echo "ðŸŽ¬ DÃ©marrage du Workflow YouTube avec Docker"
echo "============================================="

# VÃ©rifier si le fichier .env existe
if [ ! -f .env ]; then
    echo "âš ï¸  Fichier .env non trouvÃ©. CrÃ©ation d'un template..."
    cat > .env << EOF
# Configuration pour le workflow YouTube
# Remplacez YOUR_YOUTUBE_API_KEY par votre vraie clÃ© API YouTube

# YouTube API
YOUTUBE_API_KEY=YOUR_YOUTUBE_API_KEY

# MongoDB Configuration
MONGO_HOST=mongo
MONGO_PORT=27017
MONGO_USER=admin
MONGO_PASSWORD=password123
MONGO_URI=mongodb://admin:password123@mongo:27017/

# HDFS Configuration
HDFS_HOST=namenode
HDFS_PORT=9870
HDFS_NAMENODE_URL=hdfs://namenode:9000

# Spark Configuration
SPARK_MASTER_URL=spark://spark-master:7077
EOF
    echo "âœ… Fichier .env crÃ©Ã©. Veuillez y ajouter votre clÃ© API YouTube."
    echo "ðŸ’¡ Ã‰ditez le fichier .env et remplacez YOUR_YOUTUBE_API_KEY par votre vraie clÃ©."
    exit 1
fi

# VÃ©rifier si la clÃ© API YouTube est configurÃ©e
if grep -q "YOUR_YOUTUBE_API_KEY" .env; then
    echo "âŒ Veuillez configurer votre clÃ© API YouTube dans le fichier .env"
    echo "ðŸ’¡ Remplacez YOUR_YOUTUBE_API_KEY par votre vraie clÃ© API YouTube"
    exit 1
fi

echo "âœ… Configuration validÃ©e"

# DÃ©marrer l'infrastructure Docker
echo "ðŸ³ DÃ©marrage de l'infrastructure Docker..."
docker-compose up -d

# Attendre que les services soient prÃªts
echo "â³ Attente du dÃ©marrage des services (30 secondes)..."
sleep 30

# VÃ©rifier l'Ã©tat des services
echo "ðŸ” VÃ©rification de l'Ã©tat des services..."
docker-compose ps

# Attendre que MongoDB soit prÃªt
echo "â³ Attente que MongoDB soit prÃªt..."
until docker exec datalake-mongo mongosh --eval "db.runCommand('ping')" > /dev/null 2>&1; do
    echo "   En attente de MongoDB..."
    sleep 5
done
echo "âœ… MongoDB est prÃªt"

# Attendre que HDFS soit prÃªt
echo "â³ Attente que HDFS soit prÃªt..."
until curl -s http://localhost:9870 > /dev/null 2>&1; do
    echo "   En attente de HDFS..."
    sleep 5
done
echo "âœ… HDFS est prÃªt"

# Attendre que Spark soit prÃªt
echo "â³ Attente que Spark soit prÃªt..."
until curl -s http://localhost:8086 > /dev/null 2>&1; do
    echo "   En attente de Spark..."
    sleep 5
done
echo "âœ… Spark est prÃªt"

# ExÃ©cuter le workflow YouTube
echo "ðŸŽ¬ ExÃ©cution du workflow YouTube..."
docker exec -it datalake-myflow python examples/youtube_ingestion_workflow.py

echo ""
echo "âœ… Workflow terminÃ©!"
echo "ðŸ“Š Consultez les logs ci-dessus pour les rÃ©sultats dÃ©taillÃ©s"
echo ""
echo "ðŸ”— Interfaces disponibles:"
echo "   - MongoDB Express: http://localhost:8082 (admin/admin)"
echo "   - HDFS NameNode: http://localhost:9870"
echo "   - Spark Master: http://localhost:8086"
echo "   - Spark Worker: http://localhost:8087"
